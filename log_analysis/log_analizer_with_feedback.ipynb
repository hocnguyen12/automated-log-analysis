{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46781710",
   "metadata": {},
   "source": [
    "# Unified Log Analyzer with Classification, FAISS Retrieval, and Feedback Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e49b7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 15:41:06.270201: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 15:41:06.272717: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-16 15:41:06.304849: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-16 15:41:06.304875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-16 15:41:06.305822: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 15:41:06.311828: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-16 15:41:06.312816: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-16 15:41:07.071995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# --- Config Paths ---\n",
    "original_data_path = Path(\"structured_failures.json\")\n",
    "feedback_data_path = Path(\"feedback_log.jsonl\")\n",
    "model_path = Path(\"model/latest_classifier.pkl\")\n",
    "vectorizer_path = Path(\"model/latest_vectorizer.pkl\")\n",
    "faiss_index_path = Path(\"model/latest_faiss.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57031d64",
   "metadata": {},
   "source": [
    "## Step 1: Load original and feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e895f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Robot Framework test report...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data from Robot Framework test report...\")\n",
    "with open(original_data_path, \"r\") as f:\n",
    "    base_data = json.load(f)\n",
    "\n",
    "print(\"Loading data from User Feedback...\")\n",
    "feedback_entries = []\n",
    "if feedback_data_path.exists():\n",
    "    with open(feedback_data_path, \"r\") as f:\n",
    "        feedback_entries = [json.loads(line) for line in f if line.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4b2fde",
   "metadata": {},
   "source": [
    "NOTE :\n",
    "\n",
    "- Here `original_data_path` contains test fails that serve as a learning dataset\n",
    "\n",
    "Eventually, we can take tests from multiple test executions (multiple `output.xml`) and merge it into a single `.json` file that will be the large dataset with all the training data\n",
    "\n",
    "- `feedback_data_path` is another `.json` file that contains corrections from the user\n",
    "\n",
    "These corrections come from the current test execution (tests that have just been run and now the user is correcting the fails), when a prediction is done, the user tries and fix the bug, the correction from the user is added to the learning data for the very next fail analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b772400",
   "metadata": {},
   "source": [
    "## Step 1.5: Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be650ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling data (fail -> fix)...\n"
     ]
    }
   ],
   "source": [
    "def auto_label_fix_category(data):\n",
    "    for item in data:\n",
    "        if \"fix_category\" not in item or not item[\"fix_category\"]:\n",
    "            error = item[\"error\"].lower()\n",
    "            if \"missing\" in error and \"argument\" in error:\n",
    "                item[\"fix_category\"] = \"missing_argument\"\n",
    "            elif \"not found\" in error or \"selector\" in error:\n",
    "                item[\"fix_category\"] = \"invalid_selector\"\n",
    "            elif \"assert\" in error or \"should be equal\" in error:\n",
    "                item[\"fix_category\"] = \"assertion_failed\"\n",
    "            elif \"timeout\" in error:\n",
    "                item[\"fix_category\"] = \"timeout\"\n",
    "            elif \"connection\" in error:\n",
    "                item[\"fix_category\"] = \"connection_error\"\n",
    "            else:\n",
    "                item[\"fix_category\"] = \"other\"\n",
    "    return data\n",
    "\n",
    "print(\"Labeling data (fail -> fix)...\")\n",
    "base_data = auto_label_fix_category(base_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b99ea",
   "metadata": {},
   "source": [
    "## Step 2: Merge structured + feedback into unified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627baf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training data (x=fail, y=fix category)...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merged = []\n",
    "\n",
    "def build_log_text(item):\n",
    "    msg = f\"Test name: {item['test_name']}\\n\"\n",
    "    msg += f\"Doc: {item.get('doc', '')}\\n\"\n",
    "    msg += f\"Error: {item['error']}\\n\"\n",
    "    for step in item.get(\"steps\", []):\n",
    "        msg += f\"Step: {step['keyword']}\\n\"\n",
    "        msg += f\"Args: {' '.join(step['args'])}\\n\"\n",
    "        msg += f\"Status: {step['status']}\\n\"\n",
    "        if step.get(\"doc\"):\n",
    "            msg += f\"Doc: {step['doc']}\\n\"\n",
    "        if step.get(\"messages\"):\n",
    "            msg += f\"Messages: {' | '.join(step['messages'])}\\n\"\n",
    "    return msg\n",
    "\n",
    "print(\"preparing training data (x=fail, y=fix_category)...\")\n",
    "for item in base_data:\n",
    "    merged.append({\n",
    "        \"log_text\": build_log_text(item),\n",
    "        \"fix_category\": item[\"fix_category\"]\n",
    "    })\n",
    "\n",
    "# For tests that have positive feedback OR correction/actual fix informed by the user\n",
    "# -> add the test to training data\n",
    "for fb in feedback_entries:\n",
    "    if fb.get(\"feedback\") == \"correct\" or fb.get(\"actual_category\"):\n",
    "        merged.append({\n",
    "            \"log_text\": fb[\"log_text\"],\n",
    "            \"fix_category\": fb.get(\"actual_category\", fb[\"predicted_category\"])\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3af597f",
   "metadata": {},
   "source": [
    "## Step 3: Train or reload classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90848dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [r[\"log_text\"] for r in merged]\n",
    "labels = [r[\"fix_category\"] for r in merged]\n",
    "\n",
    "if model_path.exists() and vectorizer_path.exists():\n",
    "    print(\"Existing model found, loading model...\")\n",
    "    clf = joblib.load(model_path)\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "else:\n",
    "    print(\"No existing model found, training model...\")\n",
    "    vectorizer = TfidfVectorizer(max_features=500, stop_words=\"english\")\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    joblib.dump(clf, model_path)\n",
    "    joblib.dump(vectorizer, vectorizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61075cef",
   "metadata": {},
   "source": [
    "## Step 4: Rebuild FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291b103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyenvh/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "print(\"Building FAISS index (similarity retrieval)...\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(texts, show_progress_bar=False, normalize_embeddings=True)\n",
    "faiss_index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss_index.add(np.array(embeddings))\n",
    "faiss.write_index(faiss_index, str(faiss_index_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb19272",
   "metadata": {},
   "source": [
    "## Step 5: Predict on new fail\n",
    " You can replace this with live input or loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Suggested Fix Category: missing_argument\n"
     ]
    }
   ],
   "source": [
    "new_data = {\n",
    "    \"test_name\": \"Connect without API key\",\n",
    "    \"error\": \"TypeError: TestObject.__init__() missing 1 required positional argument: 'api_key'\",\n",
    "    \"doc\": \"Attempts to connect to the server without providing API key.\",\n",
    "    \"steps\": [\n",
    "        {\n",
    "            \"keyword\": \"Connect\",\n",
    "            \"args\": [\"http://localhost\"],\n",
    "            \"status\": \"FAIL\",\n",
    "            \"doc\": \"Connects to backend server using TestObject\",\n",
    "            \"messages\": [\"Connecting to http://localhost\", \"Exception raised: missing 'api_key'\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "log_text = build_log_text(new_data)\n",
    "\n",
    "print(\"Predicting fix for new fail...\")\n",
    "new_vec = vectorizer.transform([log_text])\n",
    "pred = clf.predict(new_vec)\n",
    "print(\"\\n Suggested Fix Category:\", pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e513791",
   "metadata": {},
   "source": [
    "## Step 6: Retrieve similar logs via FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Top 3 similar failures:\n",
      "\n",
      "#1 (Score: 0.66)\n",
      "Log: Test name: Update User with Admin Rights Doc: Changes Password of an existing user. Error: Parent suite setup failed: TypeError: TestObject.__init__() missing 1 required positional argument: 'api_key' ...\n",
      "Fix Category: missing_argument\n",
      "\n",
      "#2 (Score: 0.65)\n",
      "Log: Test name: Access Other Users Details With User Rights Doc: Tests does fail, due to insufficiant rights... Error: Parent suite setup failed: TypeError: TestObject.__init__() missing 1 required positional argument: 'api_key' ...\n",
      "Fix Category: missing_argument\n",
      "\n",
      "#3 (Score: 0.65)\n",
      "Log: Test name: Access All Users With Admin Rights Doc: Tests if all users can be accessed with Admin User. Error: Parent suite setup failed: TypeError: TestObject.__init__() missing 1 required positional argument: 'api_key' ...\n",
      "Fix Category: missing_argument\n"
     ]
    }
   ],
   "source": [
    "print(\"Looking for similar fails...\")\n",
    "query_embedding = model.encode([log_text], normalize_embeddings=True)\n",
    "D, I = faiss_index.search(np.array(query_embedding), k=3)\n",
    "\n",
    "print(\"\\n Top 3 similar failures:\")\n",
    "for rank, idx in enumerate(I[0]):\n",
    "    print(f\"\\n#{rank+1} (Score: {D[0][rank]:.2f})\")\n",
    "    print(\"Log:\", texts[idx][:300].replace(\"\\n\", \" \") + \"...\")\n",
    "    print(\"Fix Category:\", labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99015c2a",
   "metadata": {},
   "source": [
    "## Step 7: Ask for feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4a876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378edd9417104d209e323fa3810a7a9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2038bcb4ecec4b24bd2c0e7f9c0ddb7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feedback = input(\"\\nWas the suggested fix correct? (y/n): \")\n",
    "\n",
    "actual = None\n",
    "if feedback.lower() == \"n\":  # If the feedback is 'no', ask for the correct fix category\n",
    "    actual = input(\"What is the correct fix category? (type and press Enter): \")\n",
    "\n",
    "# Output user feedback\n",
    "if feedback.lower() == \"y\":\n",
    "    print(\"User confirmed the fix was correct.\")\n",
    "else:\n",
    "    print(f\"User said the fix was incorrect. The correct fix category is: {actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05345c68",
   "metadata": {},
   "source": [
    "## Step 8: Save feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"log_text\": log_text,\n",
    "    \"predicted_category\": pred[0],\n",
    "    \"feedback\": \"correct\" if feedback.lower() == \"y\" else \"wrong\",\n",
    "    \"actual_category\": actual if actual else None\n",
    "}\n",
    "\n",
    "print(\"Saving feedback from user for future predictions...\")\n",
    "with open(feedback_data_path, \"a\") as f:\n",
    "    f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"\\n✅ Feedback saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
