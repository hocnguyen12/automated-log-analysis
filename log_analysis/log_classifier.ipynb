{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab13a79",
   "metadata": {},
   "source": [
    "# Classify Robot Framework Failures into Fix Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc49d90",
   "metadata": {},
   "source": [
    "## Step 1: Load the structured failures JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"structured_failures.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b1c02",
   "metadata": {},
   "source": [
    "Add example fix categories manually based on error messages\n",
    "\n",
    "You can later update or expand these categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5337ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data:\n",
    "    error = item[\"error\"].lower()\n",
    "    if \"missing\" in error and \"argument\" in error:\n",
    "        item[\"fix_category\"] = \"missing_argument\"\n",
    "    elif \"not found\" in error or \"selector\" in error:\n",
    "        item[\"fix_category\"] = \"invalid_selector\"\n",
    "    elif \"assert\" in error or \"should be equal\" in error:\n",
    "        item[\"fix_category\"] = \"assertion_failed\"\n",
    "    elif \"timeout\" in error:\n",
    "        item[\"fix_category\"] = \"timeout\"\n",
    "    elif \"connection\" in error:\n",
    "        item[\"fix_category\"] = \"connection_error\"\n",
    "    else:\n",
    "        item[\"fix_category\"] = \"other\"\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41124e1b",
   "metadata": {},
   "source": [
    "Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3429da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for item in data:\n",
    "    msg = f\"Test name: {item['test_name']}\\n\"\n",
    "    msg += f\"Doc: {item.get('doc', '')}\\n\"\n",
    "    msg += f\"Error: {item['error']}\\n\"\n",
    "    for step in item.get(\"steps\", []):\n",
    "        msg += f\"Step: {step['keyword']}\\n\"\n",
    "        msg += f\"Args: {' '.join(step['args'])}\\n\"\n",
    "        msg += f\"Status: {step['status']}\\n\"\n",
    "        if step.get(\"doc\"):\n",
    "            msg += f\"Doc: {step['doc']}\\n\"\n",
    "        if step.get(\"messages\"):\n",
    "            msg += f\"Messages: {' | '.join(step['messages'])}\\n\"\n",
    "    records.append({\n",
    "        \"test_name\": item[\"test_name\"],\n",
    "        \"log_text\": msg,\n",
    "        \"fix_category\": item[\"fix_category\"]\n",
    "    })\n",
    "\n",
    "#print(records)\n",
    "print('\\033[1m' + \"Example log text :\" + '\\033[0m')\n",
    "print(records[len(records) - 1])\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9882d8",
   "metadata": {},
   "source": [
    "## Step 2: Embed the logs using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd17a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500, stop_words=\"english\")\n",
    "X = vectorizer.fit_transform([r[\"log_text\"] for r in records])\n",
    "y = [r[\"fix_category\"] for r in records]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc412c",
   "metadata": {},
   "source": [
    "## Step 3: Train/test split + classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bcd5d4",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f496e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f90a8e",
   "metadata": {},
   "source": [
    "## Step 5: Predict new failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d2785",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\n",
    "    \"test_name\": \"Connect without API key\",\n",
    "    \"error\": \"TypeError: TestObject.__init__() missing 1 required positional argument: 'api_key'\",\n",
    "    \"doc\": \"Attempts to connect to the server without providing API key.\",\n",
    "    \"steps\": [\n",
    "        {\n",
    "            \"keyword\": \"Connect\",\n",
    "            \"args\": [\"http://localhost\"],\n",
    "            \"status\": \"FAIL\",\n",
    "            \"depth\": 0,\n",
    "            \"doc\": \"Connects to backend server using TestObject\",\n",
    "            \"messages\": [\"Connecting to http://localhost\", \"Exception raised: missing 'api_key'\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "log_text = f\"Test name: {new_data['test_name']}\\n\"\n",
    "log_text += f\"Doc: {new_data['doc']}\\n\"\n",
    "log_text += f\"Error: {new_data['error']}\\n\"\n",
    "for step in new_data[\"steps\"]:\n",
    "    log_text += f\"Step: {step['keyword']}\\n\"\n",
    "    log_text += f\"Args: {' '.join(step['args'])}\\n\"\n",
    "    log_text += f\"Status: {step['status']}\\n\"\n",
    "    if step.get(\"doc\"):\n",
    "        log_text += f\"Doc: {step['doc']}\\n\"\n",
    "    if step.get(\"messages\"):\n",
    "        log_text += f\"Messages: {' | '.join(step['messages'])}\\n\"\n",
    "\n",
    "print('\\033[1m' + \"New log text :\\n\" + '\\033[0m' + log_text)\n",
    "\n",
    "new_vec = vectorizer.transform([log_text])\n",
    "pred = clf.predict(new_vec)\n",
    "print(\"Prediction:\", pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e6189",
   "metadata": {},
   "source": [
    "## Step 6: Similarity Retrieval with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Reuse the same training set with structured log_texts\n",
    "log_texts = [r[\"log_text\"] for r in records]\n",
    "metadata = [(r[\"test_name\"], r[\"fix_category\"]) for r in records]\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(log_texts, show_progress_bar=True, normalize_embeddings=True)\n",
    "\n",
    "# Build FAISS index\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])  # use cosine similarity with normalized vectors\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# Encode query the same way\n",
    "query_embedding = model.encode([log_text], normalize_embeddings=True)\n",
    "D, I = index.search(query_embedding, k=3)\n",
    "\n",
    "print(\"\\nTop 3 similar past failures:\")\n",
    "for rank, idx in enumerate(I[0]):\n",
    "    print(f\"\\n#{rank+1}\")\n",
    "    print(\"Test:\", metadata[idx][0])\n",
    "    print(\"Fix Category:\", metadata[idx][1])\n",
    "    print(\"Similarity Score:\", D[0][rank])\n",
    "    print(\"Log Snippet:\\n\", log_texts[idx][:400], \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
